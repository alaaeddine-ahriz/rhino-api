#!/usr/bin/env python3
"""
Script de test complet pour le systÃ¨me de mail automatisÃ©
Workflow: envoi -> rÃ©ponse -> Ã©valuation -> envoi rÃ©sultat
"""

import time
import logging
import argparse
from typing import List, Dict, Any, Optional
from database_utils import get_student_by_id, get_all_students, print_database_info
from send_questions import send_question_from_api, test_api_connection
from read_replies import read_replies, get_unread_count
from evaluate_responses import evaluate_pending_responses, print_evaluation_report
from send_evaluation import send_evaluations_for_pending_responses, print_evaluation_send_report
from utils import load_conversations, save_conversations

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

class EmailWorkflowTester:
    """Classe pour tester le workflow complet du systÃ¨me d'email"""
    
    def __init__(self):
        self.conversations_at_start = {}
        self.test_session_id = int(time.time())
        
    def setup_test_environment(self):
        """PrÃ©pare l'environnement de test"""
        logger.info("ğŸ”§ Configuration de l'environnement de test...")
        
        # Sauvegarder l'Ã©tat initial des conversations
        self.conversations_at_start = load_conversations().copy()
        
        # VÃ©rifier la connexion API
        if not test_api_connection():
            logger.error("âŒ Impossible de se connecter Ã  l'API")
            return False
        
        logger.info("âœ… Environnement de test configurÃ©")
        return True
    
    def send_question_to_student_by_id(self, user_id: int) -> bool:
        """
        Envoie une question Ã  un Ã©tudiant en rÃ©cupÃ©rant son email depuis la base
        
        Args:
            user_id: ID de l'Ã©tudiant
        
        Returns:
            bool: True si succÃ¨s
        """
        logger.info(f"ğŸ“¤ Envoi d'une question Ã  l'Ã©tudiant ID {user_id}")
        
        # RÃ©cupÃ©rer les informations de l'Ã©tudiant
        student = get_student_by_id(user_id)
        if not student:
            logger.error(f"âŒ Ã‰tudiant avec ID {user_id} non trouvÃ© dans la base")
            return False
        
        email = student.get("email")
        if not email:
            logger.error(f"âŒ Email manquant pour l'Ã©tudiant {student.get('username')}")
            return False
        
        logger.info(f"ğŸ‘¤ Ã‰tudiant trouvÃ©: {student['username']} ({email})")
        logger.info(f"ğŸ“š Abonnements: {', '.join(student['subscriptions'])}")
        
        # Envoyer la question
        success = send_question_from_api(
            to=email,
            user_id=user_id
        )
        
        if success:
            logger.info(f"âœ… Question envoyÃ©e avec succÃ¨s Ã  {student['username']}")
        else:
            logger.error(f"âŒ Ã‰chec de l'envoi Ã  {student['username']}")
        
        return success
    
    def wait_for_responses(self, timeout_minutes: int = 5) -> int:
        """
        Attend les rÃ©ponses des Ã©tudiants (en mode test, on peut simuler)
        
        Args:
            timeout_minutes: DÃ©lai d'attente maximum en minutes
        
        Returns:
            int: Nombre de nouvelles rÃ©ponses reÃ§ues
        """
        logger.info(f"â³ Attente de rÃ©ponses (max {timeout_minutes} min)...")
        
        start_time = time.time()
        total_new_responses = 0
        
        while time.time() - start_time < timeout_minutes * 60:
            # VÃ©rifier les nouvelles rÃ©ponses
            unread_count = get_unread_count()
            
            if unread_count > 0:
                logger.info(f"ğŸ“¨ {unread_count} nouveau(x) message(s) dÃ©tectÃ©(s)")
                new_responses = self.process_new_responses()
                total_new_responses += new_responses
                
                if new_responses > 0:
                    logger.info(f"ğŸ“¥ {new_responses} rÃ©ponse(s) traitÃ©e(s)")
                    break
            
            # Attendre 30 secondes avant de vÃ©rifier Ã  nouveau
            time.sleep(30)
        
        if total_new_responses == 0:
            logger.info("â„¹ï¸ Aucune nouvelle rÃ©ponse reÃ§ue dans le dÃ©lai imparti")
        
        return total_new_responses
    
    def process_new_responses(self) -> int:
        """
        Traite les nouvelles rÃ©ponses reÃ§ues
        
        Returns:
            int: Nombre de rÃ©ponses traitÃ©es
        """
        logger.info("ğŸ“¥ Traitement des nouvelles rÃ©ponses...")
        
        try:
            # Lire les rÃ©ponses
            read_replies()
            
            # Compter les nouvelles rÃ©ponses
            conversations = load_conversations()
            new_responses = 0
            
            for conv in conversations.values():
                if conv.get("response") and not conv.get("evaluated"):
                    new_responses += 1
            
            logger.info(f"ğŸ“Š {new_responses} nouvelle(s) rÃ©ponse(s) non Ã©valuÃ©e(s)")
            return new_responses
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors du traitement des rÃ©ponses: {e}")
            return 0
    
    def evaluate_all_responses(self) -> int:
        """
        Ã‰value toutes les rÃ©ponses en attente
        
        Returns:
            int: Nombre de rÃ©ponses Ã©valuÃ©es
        """
        logger.info("ğŸ¤– Ã‰valuation des rÃ©ponses en attente...")
        
        try:
            evaluated_count = evaluate_pending_responses()
            
            if evaluated_count > 0:
                logger.info(f"âœ… {evaluated_count} rÃ©ponse(s) Ã©valuÃ©e(s)")
            else:
                logger.info("â„¹ï¸ Aucune rÃ©ponse en attente d'Ã©valuation")
            
            return evaluated_count
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'Ã©valuation: {e}")
            return 0
    
    def send_evaluation_results(self) -> int:
        """
        Envoie les rÃ©sultats d'Ã©valuation aux Ã©tudiants
        
        Returns:
            int: Nombre d'Ã©valuations envoyÃ©es
        """
        logger.info("ğŸ“§ Envoi des rÃ©sultats d'Ã©valuation...")
        
        try:
            sent_count = send_evaluations_for_pending_responses()
            
            if sent_count > 0:
                logger.info(f"âœ… {sent_count} Ã©valuation(s) envoyÃ©e(s)")
            else:
                logger.info("â„¹ï¸ Aucune Ã©valuation en attente d'envoi")
            
            return sent_count
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'envoi des Ã©valuations: {e}")
            return 0
    
    def run_complete_workflow(self, user_id: int, wait_for_response: bool = True) -> Dict[str, Any]:
        """
        Execute le workflow complet pour un Ã©tudiant
        
        Args:
            user_id: ID de l'Ã©tudiant
            wait_for_response: Si True, attend les rÃ©ponses
        
        Returns:
            Dict avec les rÃ©sultats du workflow
        """
        logger.info(f"ğŸš€ DÃ©marrage du workflow complet pour l'Ã©tudiant ID {user_id}")
        
        results = {
            "user_id": user_id,
            "question_sent": False,
            "responses_received": 0,
            "responses_evaluated": 0,
            "evaluations_sent": 0,
            "success": False
        }
        
        # 1. Envoyer la question
        logger.info("ğŸ“¤ Phase 1: Envoi de la question")
        results["question_sent"] = self.send_question_to_student_by_id(user_id)
        
        if not results["question_sent"]:
            logger.error("âŒ Ã‰chec de l'envoi de la question. ArrÃªt du workflow.")
            return results
        
        # 2. Attendre et traiter les rÃ©ponses (si demandÃ©)
        if wait_for_response:
            logger.info("ğŸ“¥ Phase 2: Attente et traitement des rÃ©ponses")
            results["responses_received"] = self.wait_for_responses(timeout_minutes=10)
        else:
            logger.info("ğŸ“¥ Phase 2: Traitement des rÃ©ponses existantes")
            results["responses_received"] = self.process_new_responses()
        
        # 3. Ã‰valuer les rÃ©ponses
        logger.info("ğŸ¤– Phase 3: Ã‰valuation des rÃ©ponses")
        results["responses_evaluated"] = self.evaluate_all_responses()
        
        # 4. Envoyer les Ã©valuations
        logger.info("ğŸ“§ Phase 4: Envoi des Ã©valuations")
        results["evaluations_sent"] = self.send_evaluation_results()
        
        # 5. DÃ©terminer le succÃ¨s
        results["success"] = (
            results["question_sent"] and 
            (results["responses_received"] > 0 or not wait_for_response) and
            results["responses_evaluated"] > 0 and
            results["evaluations_sent"] > 0
        )
        
        logger.info(f"âœ… Workflow terminÃ© - SuccÃ¨s: {results['success']}")
        return results
    
    def run_batch_workflow(self, user_ids: List[int]) -> List[Dict[str, Any]]:
        """
        Execute le workflow pour plusieurs Ã©tudiants
        
        Args:
            user_ids: Liste des IDs d'Ã©tudiants
        
        Returns:
            Liste des rÃ©sultats pour chaque Ã©tudiant
        """
        logger.info(f"ğŸš€ DÃ©marrage du workflow batch pour {len(user_ids)} Ã©tudiant(s)")
        
        results = []
        
        for user_id in user_ids:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“‹ Traitement de l'Ã©tudiant ID {user_id}")
            logger.info(f"{'='*60}")
            
            result = self.run_complete_workflow(user_id, wait_for_response=False)
            results.append(result)
            
            # Pause entre les Ã©tudiants
            time.sleep(2)
        
        # RÃ©sumÃ© des rÃ©sultats
        self.print_batch_summary(results)
        
        return results
    
    def print_batch_summary(self, results: List[Dict[str, Any]]):
        """Affiche un rÃ©sumÃ© des rÃ©sultats batch"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š RÃ‰SUMÃ‰ DU WORKFLOW BATCH")
        logger.info("="*60)
        
        total_students = len(results)
        questions_sent = sum(1 for r in results if r["question_sent"])
        responses_received = sum(r["responses_received"] for r in results)
        responses_evaluated = sum(r["responses_evaluated"] for r in results)
        evaluations_sent = sum(r["evaluations_sent"] for r in results)
        successful_workflows = sum(1 for r in results if r["success"])
        
        logger.info(f"ğŸ‘¥ Total Ã©tudiants: {total_students}")
        logger.info(f"ğŸ“¤ Questions envoyÃ©es: {questions_sent}/{total_students}")
        logger.info(f"ğŸ“¥ RÃ©ponses reÃ§ues: {responses_received}")
        logger.info(f"ğŸ¤– RÃ©ponses Ã©valuÃ©es: {responses_evaluated}")
        logger.info(f"ğŸ“§ Ã‰valuations envoyÃ©es: {evaluations_sent}")
        logger.info(f"âœ… Workflows rÃ©ussis: {successful_workflows}/{total_students}")
        
        success_rate = round(successful_workflows / total_students * 100, 2) if total_students > 0 else 0
        logger.info(f"ğŸ“Š Taux de succÃ¨s: {success_rate}%")
        
        logger.info("="*60)
    
    def generate_final_report(self):
        """GÃ©nÃ¨re un rapport final complet"""
        logger.info("\n" + "ğŸ”" * 30)
        logger.info("RAPPORT FINAL COMPLET")
        logger.info("ğŸ”" * 30)
        
        # Informations base de donnÃ©es
        print_database_info()
        
        # Rapport d'Ã©valuation
        print_evaluation_report()
        
        # Rapport d'envoi des Ã©valuations
        print_evaluation_send_report()

def main():
    """Fonction principale avec interface CLI"""
    parser = argparse.ArgumentParser(description="Test du workflow complet du systÃ¨me de mail")
    
    subparsers = parser.add_subparsers(dest='command', help='Commandes disponibles')
    
    # Test simple
    simple_parser = subparsers.add_parser('simple', help='Test simple avec un Ã©tudiant')
    simple_parser.add_argument('--user-id', type=int, required=True, help='ID de l\'Ã©tudiant')
    simple_parser.add_argument('--no-wait', action='store_true', help='Ne pas attendre de rÃ©ponse')
    
    # Test batch
    batch_parser = subparsers.add_parser('batch', help='Test batch avec plusieurs Ã©tudiants')
    batch_parser.add_argument('--user-ids', nargs='+', type=int, help='IDs des Ã©tudiants')
    batch_parser.add_argument('--all-students', action='store_true', help='Tester tous les Ã©tudiants')
    
    # Monitoring
    monitor_parser = subparsers.add_parser('monitor', help='Mode surveillance')
    monitor_parser.add_argument('--interval', type=int, default=60, help='Intervalle en secondes')
    
    # Rapport
    report_parser = subparsers.add_parser('report', help='GÃ©nÃ©rer un rapport')
    
    args = parser.parse_args()
    
    # CrÃ©er le testeur
    tester = EmailWorkflowTester()
    
    # Configuration de l'environnement
    if not tester.setup_test_environment():
        logger.error("âŒ Impossible de configurer l'environnement de test")
        return
    
    if args.command == 'simple':
        # Test simple
        wait_response = not args.no_wait
        result = tester.run_complete_workflow(args.user_id, wait_for_response=wait_response)
        
        if result["success"]:
            logger.info("ğŸ‰ Test rÃ©ussi!")
        else:
            logger.error("ğŸ’¥ Test Ã©chouÃ©")
    
    elif args.command == 'batch':
        # Test batch
        if args.all_students:
            students = get_all_students()
            user_ids = [s["id"] for s in students]
            logger.info(f"ğŸ“‹ Test avec tous les Ã©tudiants: {len(user_ids)} trouvÃ©s")
        elif args.user_ids:
            user_ids = args.user_ids
        else:
            logger.error("âŒ SpÃ©cifiez --user-ids ou --all-students")
            return
        
        results = tester.run_batch_workflow(user_ids)
        
        successful = sum(1 for r in results if r["success"])
        total = len(results)
        logger.info(f"ğŸ¯ RÃ©sultat final: {successful}/{total} workflows rÃ©ussis")
    
    elif args.command == 'monitor':
        # Mode surveillance
        logger.info(f"ğŸ‘ï¸ Mode surveillance activÃ© (intervalle: {args.interval}s)")
        
        try:
            while True:
                logger.info("ğŸ”„ VÃ©rification pÃ©riodique...")
                
                # Traiter les rÃ©ponses
                responses = tester.process_new_responses()
                if responses > 0:
                    # Ã‰valuer et envoyer
                    evaluated = tester.evaluate_all_responses()
                    sent = tester.send_evaluation_results()
                    logger.info(f"ğŸ“Š TraitÃ©: {responses} rÃ©ponses, {evaluated} Ã©valuations, {sent} envois")
                
                time.sleep(args.interval)
                
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ Surveillance arrÃªtÃ©e")
    
    elif args.command == 'report':
        # GÃ©nÃ©rer un rapport
        tester.generate_final_report()
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 