#!/usr/bin/env python3
"""
SystÃ¨me de gestion des emails automatisÃ©
Orchestrateur principal pour l'envoi de questions et l'Ã©valuation des rÃ©ponses
"""

import time
import logging
import argparse
from typing import List, Dict, Any
from send_questions import (
    send_daily_challenge_to_user, 
    send_subject_challenge, 
    test_api_connection
)
from read_replies import read_replies, get_unread_count
from evaluate_responses import evaluate_pending_responses, print_evaluation_report
from utils import load_conversations

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

def send_question_to_student(email: str, user_id: int = None, matiere: str = None) -> bool:
    """
    Envoie une question Ã  un Ã©tudiant
    
    Args:
        email: Email de l'Ã©tudiant
        user_id: ID de l'utilisateur (pour challenge personnalisÃ©)
        matiere: MatiÃ¨re spÃ©cifique (optionnel)
    
    Returns:
        bool: True si envoyÃ© avec succÃ¨s
    """
    logger.info(f"ğŸ“¤ Envoi d'une question Ã  {email}")
    
    if user_id:
        success = send_daily_challenge_to_user(email, user_id)
    elif matiere:
        success = send_subject_challenge(email, matiere)
    else:
        logger.error("âŒ user_id ou matiere doit Ãªtre spÃ©cifiÃ©")
        return False
    
    if success:
        logger.info(f"âœ… Question envoyÃ©e avec succÃ¨s Ã  {email}")
    else:
        logger.error(f"âŒ Ã‰chec de l'envoi Ã  {email}")
    
    return success

def send_questions_to_multiple_students(students: List[Dict[str, Any]]) -> Dict[str, bool]:
    """
    Envoie des questions Ã  plusieurs Ã©tudiants
    
    Args:
        students: Liste de dictionnaires avec 'email', 'user_id' (optionnel), 'matiere' (optionnel)
    
    Returns:
        Dict avec l'email comme clÃ© et le rÃ©sultat (bool) comme valeur
    """
    results = {}
    
    logger.info(f"ğŸ“¤ Envoi de questions Ã  {len(students)} Ã©tudiant(s)")
    
    for student in students:
        email = student.get('email')
        user_id = student.get('user_id')
        matiere = student.get('matiere')
        
        if not email:
            logger.warning("âš ï¸ Email manquant pour un Ã©tudiant")
            continue
        
        result = send_question_to_student(email, user_id, matiere)
        results[email] = result
        
        # Pause entre les envois pour Ã©viter le spam
        time.sleep(1)
    
    # RÃ©sumÃ© des envois
    successful = sum(1 for success in results.values() if success)
    failed = len(results) - successful
    
    logger.info(f"ğŸ“Š RÃ©sumÃ© des envois: {successful} succÃ¨s, {failed} Ã©checs")
    
    return results

def process_replies() -> int:
    """
    Traite les rÃ©ponses reÃ§ues
    
    Returns:
        Nombre de nouvelles rÃ©ponses traitÃ©es
    """
    logger.info("ğŸ“¥ VÃ©rification des nouvelles rÃ©ponses...")
    
    # VÃ©rifier le nombre de messages non lus
    unread_count = get_unread_count()
    logger.info(f"ğŸ“¨ {unread_count} message(s) non lu(s) trouvÃ©(s)")
    
    if unread_count == 0:
        logger.info("â„¹ï¸ Aucune nouvelle rÃ©ponse Ã  traiter")
        return 0
    
    # Lire les rÃ©ponses
    read_replies()
    
    return unread_count

def evaluate_all_responses() -> int:
    """
    Ã‰value toutes les rÃ©ponses en attente
    
    Returns:
        Nombre de rÃ©ponses Ã©valuÃ©es
    """
    logger.info("ğŸ¤– Ã‰valuation des rÃ©ponses en attente...")
    
    count = evaluate_pending_responses()
    
    if count > 0:
        logger.info(f"âœ… {count} rÃ©ponse(s) Ã©valuÃ©e(s)")
    else:
        logger.info("â„¹ï¸ Aucune rÃ©ponse en attente d'Ã©valuation")
    
    return count

def run_full_workflow(students: List[Dict[str, Any]] = None) -> None:
    """
    Execute le workflow complet: envoi -> rÃ©ception -> Ã©valuation
    
    Args:
        students: Liste optionnelle d'Ã©tudiants pour envoi groupÃ©
    """
    logger.info("ğŸš€ DÃ©marrage du workflow complet")
    
    # 1. VÃ©rifier la connexion API
    if not test_api_connection():
        logger.error("âŒ Impossible de se connecter Ã  l'API. ArrÃªt du workflow.")
        return
    
    # 2. Envoyer des questions (si spÃ©cifiÃ©)
    if students:
        logger.info("ğŸ“¤ Phase 1: Envoi des questions")
        send_questions_to_multiple_students(students)
    else:
        logger.info("â„¹ï¸ Aucun envoi de question programmÃ©")
    
    # 3. Traiter les rÃ©ponses
    logger.info("ğŸ“¥ Phase 2: Traitement des rÃ©ponses")
    new_replies = process_replies()
    
    # 4. Ã‰valuer les rÃ©ponses
    logger.info("ğŸ¤– Phase 3: Ã‰valuation des rÃ©ponses")
    evaluated = evaluate_all_responses()
    
    # 5. Afficher le rapport
    logger.info("ğŸ“Š Phase 4: GÃ©nÃ©ration du rapport")
    print_evaluation_report()
    
    logger.info(f"âœ… Workflow terminÃ©: {new_replies} nouvelles rÃ©ponses, {evaluated} Ã©valuations")

def monitor_mode(interval: int = 300) -> None:
    """
    Mode surveillance: vÃ©rifie pÃ©riodiquement les nouvelles rÃ©ponses
    
    Args:
        interval: Intervalle en secondes entre les vÃ©rifications (dÃ©faut: 5 minutes)
    """
    logger.info(f"ğŸ‘ï¸ Mode surveillance activÃ© (intervalle: {interval}s)")
    
    try:
        while True:
            logger.info("ğŸ”„ VÃ©rification pÃ©riodique...")
            
            # Traiter les rÃ©ponses
            new_replies = process_replies()
            
            # Ã‰valuer les rÃ©ponses
            if new_replies > 0:
                evaluated = evaluate_all_responses()
                logger.info(f"ğŸ“Š Traitement: {new_replies} rÃ©ponses, {evaluated} Ã©valuations")
            
            # Attendre avant la prochaine vÃ©rification
            logger.info(f"â° Prochaine vÃ©rification dans {interval} secondes")
            time.sleep(interval)
            
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Mode surveillance arrÃªtÃ© par l'utilisateur")

def main():
    """Fonction principale avec interface en ligne de commande"""
    parser = argparse.ArgumentParser(description="SystÃ¨me de gestion des emails automatisÃ©")
    
    subparsers = parser.add_subparsers(dest='command', help='Commandes disponibles')
    
    # Commande send
    send_parser = subparsers.add_parser('send', help='Envoyer une question')
    send_parser.add_argument('--email', required=True, help='Email de l\'Ã©tudiant')
    send_parser.add_argument('--user-id', type=int, help='ID de l\'utilisateur')
    send_parser.add_argument('--matiere', help='MatiÃ¨re spÃ©cifique')
    
    # Commande read
    read_parser = subparsers.add_parser('read', help='Lire les rÃ©ponses')
    
    # Commande evaluate
    eval_parser = subparsers.add_parser('evaluate', help='Ã‰valuer les rÃ©ponses')
    
    # Commande report
    report_parser = subparsers.add_parser('report', help='Afficher le rapport')
    
    # Commande workflow
    workflow_parser = subparsers.add_parser('workflow', help='ExÃ©cuter le workflow complet')
    
    # Commande monitor
    monitor_parser = subparsers.add_parser('monitor', help='Mode surveillance')
    monitor_parser.add_argument('--interval', type=int, default=300, help='Intervalle en secondes (dÃ©faut: 300)')
    
    args = parser.parse_args()
    
    if args.command == 'send':
        send_question_to_student(args.email, args.user_id, args.matiere)
    
    elif args.command == 'read':
        process_replies()
    
    elif args.command == 'evaluate':
        evaluate_all_responses()
    
    elif args.command == 'report':
        print_evaluation_report()
    
    elif args.command == 'workflow':
        run_full_workflow()
    
    elif args.command == 'monitor':
        monitor_mode(args.interval)
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 